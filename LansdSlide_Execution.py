# -*- coding: utf-8 -*-
"""Copy of LansdSlide_Execution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cbedu6AtMEtLyOdkuqOUIwaKEi-Di0LB
"""

!git clone https://github.com/iarai/Landslide4Sense-2022.git

from google.colab import files
files.upload()

# Only run this if you haven't done it yet
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Landslide4Sense-2022

!kaggle datasets download -d pypiahmad/landslide4sense-challenge

!unzip /content/Landslide4Sense-2022/landslide4sense-challenge.zip  | tqdm > /dev/null

!python Train.py --data_dir ./ --gpu_id 0

from google.colab import drive
drive.mount('/content/drive')

!mkdir -p /content/drive/MyDrive/Landslide4Sense-2022-main/exp

!cp -r /content/Landslide4Sense-2022 /content/drive/MyDrive/Landslide4Sense-2022-main/exp/exp

drive.flush_and_unmount()
drive.mount('/content/drive')

#batch500_F1_6957.pth

!python Predict.py --data_dir ./ \
               --gpu_id 0 \
               --test_list ./dataset/valid.txt \
               --snapshot_dir ./predictions/ \
               --restore_from /content/drive/MyDrive/Landslide4Sense-2022-main/exp/exp/batch500_F1_6957.pth

#batch1500_F1_6957.pth

!python Predict.py --data_dir ./ \
               --gpu_id 0 \
               --test_list ./dataset/valid.txt \
               --snapshot_dir ./predictions2/ \
               --restore_from /content/drive/MyDrive/Landslide4Sense-2022-main/exp/exp/batch1500_F1_7313.pth

#batch4000_F1_6957.pth

!python Predict.py --data_dir ./ \
               --gpu_id 0 \
               --test_list ./dataset/valid.txt \
               --snapshot_dir ./predictions2/ \
               --restore_from /content/drive/MyDrive/Landslide4Sense-2022-main/exp/exp/batch4000_F1_7491.pth

!mv ./predictions/ /content/drive/MyDrive/Landslide4Sense-2022-main

!mv ./predictions1/ /content/drive/MyDrive/Landslide4Sense-2022-main

!mv ./predictions2/ /content/drive/MyDrive/Landslide4Sense-2022-main

!git lfs install

!git clone https://huggingface.co/datasets/ibm-nasa-geospatial/Landslide4sense

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Landslide4Sense-2022/Landslide4sense

#Dataset range from 0-500

import os
import numpy as np
import h5py
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

gt_dir = "/content/Landslide4Sense-2022/Landslide4sense/annotations/validation"
pred_dir = "/content/drive/MyDrive/Landslide4Sense-2022-main/predictions"

all_preds = []
all_gts = []

for i in range(1, 246):
    gt_path = os.path.join(gt_dir, f"mask_{i}.h5")
    pred_path = os.path.join(pred_dir, f"mask_{i}.h5")

    # Load masks
    with h5py.File(gt_path, 'r') as f:
        gt = np.array(f[list(f.keys())[0]])  # assumes only one dataset per file
    with h5py.File(pred_path, 'r') as f:
        pred = np.array(f[list(f.keys())[0]])

    # Flatten and accumulate
    all_gts.append(gt.flatten())
    all_preds.append(pred.flatten())

# Concatenate all
all_gts = np.concatenate(all_gts)
all_preds = np.concatenate(all_preds)

# Compute metrics
precision = precision_score(all_gts, all_preds)
recall = recall_score(all_gts, all_preds)
f1 = f1_score(all_gts, all_preds)
accuracy = accuracy_score(all_gts, all_preds)

print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"Accuracy:  {accuracy:.4f}")

#Dataset range from 501-1500

import os
import numpy as np
import h5py
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

gt_dir = "/content/Landslide4Sense-2022/Landslide4sense/annotations/validation"
pred_dir = "/content/drive/MyDrive/Landslide4Sense-2022-main/predictions1"

all_preds = []
all_gts = []

for i in range(1, 246):
    gt_path = os.path.join(gt_dir, f"mask_{i}.h5")
    pred_path = os.path.join(pred_dir, f"mask_{i}.h5")

    # Load masks
    with h5py.File(gt_path, 'r') as f:
        gt = np.array(f[list(f.keys())[0]])  # assumes only one dataset per file
    with h5py.File(pred_path, 'r') as f:
        pred = np.array(f[list(f.keys())[0]])

    # Flatten and accumulate
    all_gts.append(gt.flatten())
    all_preds.append(pred.flatten())

# Concatenate all
all_gts = np.concatenate(all_gts)
all_preds = np.concatenate(all_preds)

# Compute metrics
precision = precision_score(all_gts, all_preds)
recall = recall_score(all_gts, all_preds)
f1 = f1_score(all_gts, all_preds)
accuracy = accuracy_score(all_gts, all_preds)

print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"Accuracy:  {accuracy:.4f}")

#Dataset range from 1501-4000

import os
import numpy as np
import h5py
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

gt_dir = "/content/Landslide4Sense-2022/Landslide4sense/annotations/validation"
pred_dir = "/content/drive/MyDrive/Landslide4Sense-2022-main/predictions2"

all_preds = []
all_gts = []

for i in range(1, 246):
    gt_path = os.path.join(gt_dir, f"mask_{i}.h5")
    pred_path = os.path.join(pred_dir, f"mask_{i}.h5")

    # Load masks
    with h5py.File(gt_path, 'r') as f:
        gt = np.array(f[list(f.keys())[0]])  # assumes only one dataset per file
    with h5py.File(pred_path, 'r') as f:
        pred = np.array(f[list(f.keys())[0]])

    # Flatten and accumulate
    all_gts.append(gt.flatten())
    all_preds.append(pred.flatten())

# Concatenate all
all_gts = np.concatenate(all_gts)
all_preds = np.concatenate(all_preds)

# Compute metrics
precision = precision_score(all_gts, all_preds)
recall = recall_score(all_gts, all_preds)
f1 = f1_score(all_gts, all_preds)
accuracy = accuracy_score(all_gts, all_preds)

print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"Accuracy:  {accuracy:.4f}")